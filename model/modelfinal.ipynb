{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, PolynomialFeatures\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.feature_selection import SelectKBest, mutual_info_regression\n",
    "from sklearn.impute import SimpleImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"D:\\\\Projects\\\\Linear Regression\\\\Dataset\\\\cars_dataset.csv\")\n",
    "\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "# Reset index before applying outlier removal\n",
    "df = df.reset_index(drop=True)\n",
    "\n",
    "# Select numerical features for outlier detection\n",
    "num_features = [\"year\", \"mileage\", \"tax\", \"mpg\", \"engineSize\"]\n",
    "\n",
    "# Compute IQR\n",
    "Q1 = df[num_features].quantile(0.25)\n",
    "Q3 = df[num_features].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "# Mask for valid data (keeping only non-outliers)\n",
    "mask = ~((df[num_features] < (Q1 - 1.5 * IQR)) | (df[num_features] > (Q3 + 1.5 * IQR))).any(axis=1)\n",
    "df = df[mask].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [\"year\", \"mileage\", \"tax\", \"mpg\", \"engineSize\", \"Make\", \"model\", \"transmission\", \"fuelType\"]\n",
    "target = \"price\"\n",
    "\n",
    "X = df[features]\n",
    "y = df[target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.log1p(y)  # Log transform target (price)\n",
    "X[\"mileage\"] = np.log1p(X[\"mileage\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X[num_features] = scaler.fit_transform(X[num_features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = OneHotEncoder(handle_unknown='ignore', sparse_output=False)\n",
    "categorical_encoded = encoder.fit_transform(X[['Make', 'model', 'transmission', 'fuelType']])\n",
    "categorical_columns = encoder.get_feature_names_out(['Make', 'model', 'transmission', 'fuelType'])\n",
    "categorical_df = pd.DataFrame(categorical_encoded, columns=categorical_columns, index=X.index)\n",
    "\n",
    "# Merge Encoded Features with Scaled Numerical Features\n",
    "X = X.drop(columns=['Make', 'model', 'transmission', 'fuelType']).reset_index(drop=True)\n",
    "X = pd.concat([X, categorical_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imputer = SimpleImputer(strategy='mean')\n",
    "X = pd.DataFrame(imputer.fit_transform(X), columns=X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selector = SelectKBest(score_func=mutual_info_regression, k=min(20, X.shape[1]))\n",
    "X_selected = selector.fit_transform(X, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poly = PolynomialFeatures(degree=2, interaction_only=True)\n",
    "X_poly = poly.fit_transform(X_selected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_poly, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Ridge(alpha=0.5)  # Fine-tuned alpha\n",
    "model.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Convert predictions back from log scale\n",
    "y_test_actual = np.expm1(y_test)\n",
    "y_pred_actual = np.expm1(y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mae = mean_absolute_error(y_test_actual, y_pred_actual)\n",
    "mse = mean_squared_error(y_test_actual, y_pred_actual)\n",
    "rmse = np.sqrt(mse)\n",
    "r2 = r2_score(y_test_actual, y_pred_actual)\n",
    "mape = np.mean(np.abs((y_test_actual - y_pred_actual) / y_test_actual)) * 100\n",
    "\n",
    "# Cross-validation for stability check\n",
    "cv_scores = cross_val_score(model, X_poly, y, cv=5, scoring='r2')\n",
    "\n",
    "# Print Performance Metrics\n",
    "print(f\"Mean Absolute Error (MAE): {mae}\")\n",
    "print(f\"Mean Squared Error (MSE): {mse}\")\n",
    "print(f\"Root Mean Squared Error (RMSE): {rmse}\")\n",
    "print(f\"R-squared (R²): {r2}\")\n",
    "print(f\"Mean Absolute Percentage Error (MAPE): {mape}%\")\n",
    "print(f\"Cross-Validation R² Score: {np.mean(cv_scores)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 5))\n",
    "sns.scatterplot(x=y_test_actual, y=y_pred_actual)\n",
    "plt.xlabel(\"Actual Prices\")\n",
    "plt.ylabel(\"Predicted Prices\")\n",
    "plt.title(\"Actual vs Predicted Car Prices\")\n",
    "plt.show()\n",
    "\n",
    "residuals = y_test_actual - y_pred_actual\n",
    "plt.figure(figsize=(8, 5))\n",
    "sns.histplot(residuals, bins=30, kde=True)\n",
    "plt.xlabel(\"Residuals\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.title(\"Residuals Distribution\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os\n",
    "\n",
    "# Ensure the \"model\" directory exists\n",
    "os.makedirs(\"model\", exist_ok=True)\n",
    "\n",
    "# Save the trained Ridge model\n",
    "with open(\"model/ridge_model.pkl\", \"wb\") as f:\n",
    "    pickle.dump(model, f)\n",
    "\n",
    "# Save preprocessing objects\n",
    "with open(\"model/scaler.pkl\", \"wb\") as f:\n",
    "    pickle.dump(scaler, f)\n",
    "\n",
    "with open(\"model/encoder.pkl\", \"wb\") as f:\n",
    "    pickle.dump(encoder, f)\n",
    "\n",
    "with open(\"model/feature_selector.pkl\", \"wb\") as f:\n",
    "    pickle.dump(selector, f)\n",
    "\n",
    "with open(\"model/poly_transform.pkl\", \"wb\") as f:\n",
    "    pickle.dump(poly, f)\n",
    "\n",
    "print(\"Model and preprocessing objects saved successfully!\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
